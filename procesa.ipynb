{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18a49ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  #Import Pandas\n",
    "import numpy as np  #Import NumPy\n",
    "import matplotlib.pylab as plt  #Import matplotlib\n",
    "import seaborn as sns  #Python data visualization library\n",
    "import soundfile as sf\n",
    "\n",
    "import os, re\n",
    "import shutil\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "\n",
    "import csv\n",
    "\n",
    "import random #2 make a random numer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from glob import glob #2 List the files in a directory\n",
    "\n",
    "import librosa  #Python package for music and audio analysis\n",
    "import librosa.display  #Python package for music and audio analysis\n",
    "import IPython.display as ipd  #2 Display audio samples\n",
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fc4311",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_dir = r'moods\\whole'\n",
    "\n",
    "out_dir = r'moods\\seg'\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b740fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our class names: ['angry', 'dark', 'epic', 'funky', 'funny', 'happy', 'horror', 'motivating', 'mysterious', 'peaceful', 'romantic', 'sad', 'suspenseful', 'upbeat']\n"
     ]
    }
   ],
   "source": [
    "class_names = os.listdir(audio_dir)\n",
    "print(\"Our class names: {}\".format(class_names,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46d343c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing speaker angry\n",
      "Processing speaker dark\n",
      "Processing speaker epic\n",
      "Processing speaker funky\n",
      "Processing speaker funny\n",
      "Processing speaker happy\n",
      "Processing speaker horror\n",
      "Processing speaker motivating\n",
      "Processing speaker mysterious\n",
      "Processing speaker peaceful\n",
      "Processing speaker romantic\n",
      "Processing speaker sad\n",
      "Processing speaker suspenseful\n",
      "Processing speaker upbeat\n",
      "Found 795 files belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "audio_paths = []\n",
    "labels = []\n",
    "for label, name in enumerate(class_names):\n",
    "    print(\"Processing speaker {}\".format(name,))\n",
    "    dir_path = Path(audio_dir) / name\n",
    "    speaker_sample_paths = [\n",
    "        os.path.join(dir_path, filepath)\n",
    "        for filepath in os.listdir(dir_path)\n",
    "        if filepath.endswith(\".mp3\")\n",
    "    ]\n",
    "    audio_paths += speaker_sample_paths\n",
    "    labels += [label] * len(speaker_sample_paths)\n",
    "\n",
    "print(\n",
    "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b17f3e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting Champagne_at_Sunset.mp3_0.mp3\n",
      "exporting Champagne_at_Sunset.mp3_1.mp3\n",
      "exporting Champagne_at_Sunset.mp3_2.mp3\n",
      "exporting Champagne_at_Sunset.mp3_3.mp3\n",
      "exporting Champagne_at_Sunset.mp3_4.mp3\n",
      "exporting Champagne_at_Sunset.mp3_5.mp3\n",
      "exporting Classic_Love_Scene.mp3_0.mp3\n",
      "exporting Classic_Love_Scene.mp3_1.mp3\n",
      "exporting Classic_Love_Scene.mp3_2.mp3\n",
      "exporting Classic_Love_Scene.mp3_3.mp3\n",
      "exporting Classic_Love_Scene.mp3_4.mp3\n",
      "exporting Classic_Love_Scene.mp3_5.mp3\n",
      "exporting Classic_Love_Scene.mp3_6.mp3\n",
      "exporting Fancy_Date.mp3_0.mp3\n",
      "exporting Fancy_Date.mp3_1.mp3\n",
      "exporting Fancy_Date.mp3_2.mp3\n",
      "exporting Fancy_Date.mp3_3.mp3\n",
      "exporting Fancy_Date.mp3_4.mp3\n",
      "exporting Fancy_Date.mp3_5.mp3\n",
      "exporting Fancy_Date.mp3_6.mp3\n",
      "exporting Fireside_Date.mp3_0.mp3\n",
      "exporting Fireside_Date.mp3_1.mp3\n",
      "exporting Fireside_Date.mp3_2.mp3\n",
      "exporting Fireside_Date.mp3_3.mp3\n",
      "exporting Fireside_Date.mp3_4.mp3\n",
      "exporting Fireside_Date.mp3_5.mp3\n",
      "exporting First_Touch.mp3_0.mp3\n",
      "exporting First_Touch.mp3_1.mp3\n",
      "exporting First_Touch.mp3_2.mp3\n",
      "exporting First_Touch.mp3_3.mp3\n",
      "exporting First_Touch.mp3_4.mp3\n",
      "exporting First_Touch.mp3_5.mp3\n",
      "exporting First_Touch.mp3_6.mp3\n",
      "exporting Lounge_Bossa.mp3_0.mp3\n",
      "exporting Lounge_Bossa.mp3_1.mp3\n",
      "exporting Lounge_Bossa.mp3_2.mp3\n",
      "exporting Lounge_Bossa.mp3_3.mp3\n",
      "exporting Lounge_Bossa.mp3_4.mp3\n",
      "exporting Lounge_Bossa.mp3_5.mp3\n",
      "exporting Lovers.mp3_0.mp3\n",
      "exporting Lovers.mp3_1.mp3\n",
      "exporting Lovers.mp3_2.mp3\n",
      "exporting Lovers.mp3_3.mp3\n",
      "exporting Lovers.mp3_4.mp3\n",
      "exporting Love_Spell.mp3_0.mp3\n",
      "exporting Love_Spell.mp3_1.mp3\n",
      "exporting Love_Spell.mp3_2.mp3\n",
      "exporting Love_Spell.mp3_3.mp3\n",
      "exporting Love_Spell.mp3_4.mp3\n",
      "exporting Love_Spell.mp3_5.mp3\n",
      "exporting Move_Together.mp3_0.mp3\n",
      "exporting Move_Together.mp3_1.mp3\n",
      "exporting Move_Together.mp3_2.mp3\n",
      "exporting Move_Together.mp3_3.mp3\n",
      "exporting Move_Together.mp3_4.mp3\n",
      "exporting Night_To_Remember.mp3_0.mp3\n",
      "exporting Night_To_Remember.mp3_1.mp3\n",
      "exporting Night_To_Remember.mp3_2.mp3\n",
      "exporting Night_To_Remember.mp3_3.mp3\n",
      "exporting Night_To_Remember.mp3_4.mp3\n",
      "exporting Night_To_Remember.mp3_5.mp3\n",
      "exporting Night_To_Remember.mp3_6.mp3\n",
      "exporting Proud_And_Gentle.mp3_0.mp3\n",
      "exporting Proud_And_Gentle.mp3_1.mp3\n",
      "exporting Proud_And_Gentle.mp3_2.mp3\n",
      "exporting Proud_And_Gentle.mp3_3.mp3\n",
      "exporting Proud_And_Gentle.mp3_4.mp3\n",
      "exporting Proud_And_Gentle.mp3_5.mp3\n",
      "exporting RomanticMusic2018-11-11_-_Tender_Love_-_David_Fesliyan.mp3_0.mp3\n",
      "exporting RomanticMusic2018-11-11_-_Tender_Love_-_David_Fesliyan.mp3_1.mp3\n",
      "exporting RomanticMusic2018-11-11_-_Tender_Love_-_David_Fesliyan.mp3_2.mp3\n",
      "exporting RomanticMusic2018-11-11_-_Tender_Love_-_David_Fesliyan.mp3_3.mp3\n",
      "exporting RomanticMusic2018-11-11_-_Tender_Love_-_David_Fesliyan.mp3_4.mp3\n",
      "exporting RomanticMusic2018-11-11_-_Tender_Love_-_David_Fesliyan.mp3_5.mp3\n",
      "exporting RomanticMusic2018-11-11_-_Tender_Love_-_David_Fesliyan.mp3_6.mp3\n",
      "exporting RomanticMusic2018-11-11_-_Tender_Love_-_David_Fesliyan.mp3_7.mp3\n",
      "exporting RomanticMusic2018-11-11_-_Tender_Love_-_David_Fesliyan.mp3_8.mp3\n",
      "exporting Talk_To_Me.mp3_0.mp3\n",
      "exporting Talk_To_Me.mp3_1.mp3\n",
      "exporting Talk_To_Me.mp3_2.mp3\n",
      "exporting Talk_To_Me.mp3_3.mp3\n",
      "exporting Talk_To_Me.mp3_4.mp3\n",
      "exporting Tears_of_Joy.mp3_0.mp3\n",
      "exporting Tears_of_Joy.mp3_1.mp3\n",
      "exporting Tears_of_Joy.mp3_2.mp3\n",
      "exporting Tears_of_Joy.mp3_3.mp3\n",
      "exporting Tears_of_Joy.mp3_4.mp3\n",
      "exporting Tears_of_Joy.mp3_5.mp3\n",
      "exporting The_Two_Of_Us.mp3_0.mp3\n",
      "exporting The_Two_Of_Us.mp3_1.mp3\n",
      "exporting The_Two_Of_Us.mp3_2.mp3\n",
      "exporting The_Two_Of_Us.mp3_3.mp3\n",
      "exporting The_Two_Of_Us.mp3_4.mp3\n",
      "exporting The_Two_Of_Us.mp3_5.mp3\n",
      "exporting The_Two_Of_Us.mp3_6.mp3\n",
      "exporting The_Two_Of_Us.mp3_7.mp3\n",
      "exporting Unattainable.mp3_0.mp3\n",
      "exporting Unattainable.mp3_1.mp3\n",
      "exporting Unattainable.mp3_2.mp3\n",
      "exporting Unattainable.mp3_3.mp3\n",
      "exporting Unattainable.mp3_4.mp3\n",
      "exporting Under_A_Dim_Lantern.mp3_0.mp3\n",
      "exporting Under_A_Dim_Lantern.mp3_1.mp3\n",
      "exporting Under_A_Dim_Lantern.mp3_2.mp3\n",
      "exporting Under_A_Dim_Lantern.mp3_3.mp3\n",
      "exporting Under_A_Dim_Lantern.mp3_4.mp3\n",
      "exporting Under_A_Dim_Lantern.mp3_5.mp3\n",
      "exporting Under_A_Dim_Lantern.mp3_6.mp3\n",
      "exporting Unseen_Affection.mp3_0.mp3\n",
      "exporting Unseen_Affection.mp3_1.mp3\n",
      "exporting Unseen_Affection.mp3_2.mp3\n",
      "exporting Unseen_Affection.mp3_3.mp3\n",
      "exporting Unseen_Affection.mp3_4.mp3\n",
      "exporting Unseen_Affection.mp3_5.mp3\n",
      "exporting Unseen_Affection.mp3_6.mp3\n",
      "exporting Unseen_Affection.mp3_7.mp3\n",
      "exporting Wistful_Heart.mp3_0.mp3\n",
      "exporting Wistful_Heart.mp3_1.mp3\n",
      "exporting Wistful_Heart.mp3_2.mp3\n",
      "exporting Wistful_Heart.mp3_3.mp3\n",
      "exporting Wistful_Heart.mp3_4.mp3\n",
      "exporting Wistful_Heart.mp3_5.mp3\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(f'./moods/whole/romantic'):\n",
    "    songname = f'./moods/whole/romantic/{filename}'\n",
    "    sound = AudioSegment.from_file(Path(f'./moods/whole/romantic/'+ filename))\n",
    "    chunk_length_ms = 30000 # pydub calculates in millisec \n",
    "    chunks = make_chunks(sound,chunk_length_ms) #Make chunks of one sec \n",
    "    for i, chunk in enumerate(chunks): \n",
    "        chunk_name = \"{}_{}.mp3\".format(filename, i)\n",
    "        print (\"exporting\", chunk_name) \n",
    "        chunk.export(os.path.join(out_dir, 'romantic', chunk_name), format=\"mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa499fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"2019-11-30_-_No_More_Good_-_David_Fesliyan\", \"2020-07-24_-_Torn_-_David_Fesliyan\"]\n",
    "names = []\n",
    "for s in files:\n",
    "    m = re.search(r\"-_(\\w+)_-\", s)\n",
    "    match = m.group(0)\n",
    "    names.append(match)\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7145452c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting MIT.wav_0.wav\n",
      "exporting MIT.wav_1.wav\n",
      "exporting MIT.wav_2.wav\n",
      "exporting MIT.wav_3.wav\n",
      "exporting MIT.wav_4.wav\n",
      "exporting MIT.wav_5.wav\n",
      "exporting MIT.wav_6.wav\n",
      "exporting MIT.wav_7.wav\n",
      "exporting MIT.wav_8.wav\n",
      "exporting MIT.wav_9.wav\n",
      "exporting MIT.wav_10.wav\n",
      "exporting soong就好.wav_0.wav\n",
      "exporting soong就好.wav_1.wav\n",
      "exporting soong就好.wav_2.wav\n",
      "exporting soong就好.wav_3.wav\n",
      "exporting soong就好.wav_4.wav\n",
      "exporting soong就好.wav_5.wav\n",
      "exporting soong就好.wav_6.wav\n",
      "exporting WakeUp.wav_0.wav\n",
      "exporting WakeUp.wav_1.wav\n",
      "exporting WakeUp.wav_2.wav\n",
      "exporting WakeUp.wav_3.wav\n",
      "exporting WakeUp.wav_4.wav\n",
      "exporting WakeUp.wav_5.wav\n",
      "exporting WakeUp.wav_6.wav\n",
      "exporting WakeUp.wav_7.wav\n",
      "exporting 一起找出路.wav_0.wav\n",
      "exporting 一起找出路.wav_1.wav\n",
      "exporting 一起找出路.wav_2.wav\n",
      "exporting 一起找出路.wav_3.wav\n",
      "exporting 一起找出路b.wav_0.wav\n",
      "exporting 一起找出路b.wav_1.wav\n",
      "exporting 一起找出路b.wav_2.wav\n",
      "exporting 一起找出路b.wav_3.wav\n",
      "exporting 一起找出路b.wav_4.wav\n",
      "exporting 一起找出路b.wav_5.wav\n",
      "exporting 一起找出路b.wav_6.wav\n",
      "exporting 人在做天在看.wav_0.wav\n",
      "exporting 人在做天在看.wav_1.wav\n",
      "exporting 人在做天在看.wav_2.wav\n",
      "exporting 人在做天在看.wav_3.wav\n",
      "exporting 人在做天在看.wav_4.wav\n",
      "exporting 人在做天在看.wav_5.wav\n",
      "exporting 人在做天在看.wav_6.wav\n",
      "exporting 幸福車站.wav_0.wav\n",
      "exporting 幸福車站.wav_1.wav\n",
      "exporting 幸福車站.wav_2.wav\n",
      "exporting 幸福車站.wav_3.wav\n",
      "exporting 幸福車站.wav_4.wav\n",
      "exporting 幸福車站.wav_5.wav\n",
      "exporting 幸福車站.wav_6.wav\n",
      "exporting 幸福車站.wav_7.wav\n",
      "exporting 有你有我.wav_0.wav\n",
      "exporting 有你有我.wav_1.wav\n",
      "exporting 有你有我.wav_2.wav\n",
      "exporting 有你有我.wav_3.wav\n",
      "exporting 有你有我.wav_4.wav\n",
      "exporting 有你有我.wav_5.wav\n",
      "exporting 有你有我.wav_6.wav\n",
      "exporting 有你有我.wav_7.wav\n",
      "exporting 有你有我.wav_8.wav\n",
      "exporting 有你有我.wav_9.wav\n",
      "exporting 有你有我.wav_10.wav\n",
      "exporting 謝謝你.wav_0.wav\n",
      "exporting 謝謝你.wav_1.wav\n",
      "exporting 謝謝你.wav_2.wav\n",
      "exporting 謝謝你.wav_3.wav\n",
      "exporting 謝謝你.wav_4.wav\n",
      "exporting 謝謝你.wav_5.wav\n",
      "exporting 謝謝你.wav_6.wav\n",
      "exporting 謝謝你.wav_7.wav\n",
      "exporting 謝謝你.wav_8.wav\n",
      "exporting 謝謝你.wav_9.wav\n",
      "exporting 謝謝你.wav_10.wav\n"
     ]
    }
   ],
   "source": [
    "out_dir = r'camps'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "for filename in os.listdir(f'./ot'):\n",
    "    songname = f'./{filename}'\n",
    "    sound = AudioSegment.from_file(Path(f'./ot/'+ filename))\n",
    "    chunk_length_ms = 30000 # pydub calculates in millisec \n",
    "    chunks = make_chunks(sound,chunk_length_ms) #Make chunks of one sec \n",
    "    for i, chunk in enumerate(chunks): \n",
    "        chunk_name = \"{}_{}.wav\".format(filename, i)\n",
    "        print (\"exporting\", chunk_name) \n",
    "        chunk.export(os.path.join(out_dir, 'ot', chunk_name), format=\"wav\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = []\n",
    "labels = []\n",
    "for label, name in enumerate(class_names):\n",
    "    print(\"Processing speaker {}\".format(name,))\n",
    "    dir_path = Path(DATASET_AUDIO_PATH) / name\n",
    "    speaker_sample_paths = [\n",
    "        os.path.join(dir_path, filepath)\n",
    "        for filepath in os.listdir(dir_path)\n",
    "        if filepath.endswith(\".wav\")\n",
    "    ]\n",
    "    audio_paths += speaker_sample_paths\n",
    "    labels += [label] * len(speaker_sample_paths)\n",
    "\n",
    "print(\n",
    "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc661e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = r'.\\mp3'\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f11be559",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(f'./DPP'):\n",
    "    songname = f'./DPP/{filename}'\n",
    "    sound = AudioSegment.from_file(Path(f'./DPP/'+ filename))\n",
    "    sound.export(os.path.join(out_dir,re.sub('\\\\.wav', '.mp3', filename)), format=\"mp3\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afaec290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "y1 = np.load('./highlight/春天的花蕊_highlight.npy')\n",
    "# y2 = np.load('./mp3/春天的花蕊_highlight.npy')\n",
    "# type(np.vstack((y1,y2)))\n",
    "y1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68504df3",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'highlight\\\\DPP'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26272\\1632371576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./highlight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mhl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./highlight/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mhls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'highlight\\\\DPP'"
     ]
    }
   ],
   "source": [
    "hls = []\n",
    "for filename in os.listdir(f'./highlight'):\n",
    "    hl = np.load(Path(f'./highlight/'+filename))\n",
    "    hls.append(hl)\n",
    "hls = np.vstack(hls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee67677",
   "metadata": {},
   "outputs": [],
   "source": [
    "scs = []\n",
    "for filename in os.listdir(f'./highlight/score'):\n",
    "    sc = np.load(Path(f'./highlight/score/'+filename))\n",
    "    scs.append(sc)\n",
    "# scs = np.vstack(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc95594",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = 'filename sc_mean sc_max sc_whole'\n",
    "header = header.split()\n",
    "file = open('scores.csv', 'w', newline='', encoding='utf-8')\n",
    "with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "for filename in os.listdir(f'./highlight/score'):\n",
    "    name = f'./highlight/score/{filename}'\n",
    "    sc = np.load(Path(f'./highlight/score/'+filename))\n",
    "    to_append = f'{name} {np.mean(sc)} {np.array(sc).argmax()} {len(sc)}'    \n",
    "    file = open('scores.csv', 'a', newline='')\n",
    "    with file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(to_append.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a67d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "# mypath = r'mp3'\n",
    "# files = [f for f in os.listdir(mypath) if os.path.isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dcccb8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = out_dir = r'highlight\\seg'\n",
    "\n",
    "for f in enumerate(files):\n",
    "    songname = f[1]\n",
    "    sound = AudioSegment.from_file(Path(f'./mp3/'+ songname), start_second = hls[f[0]][0], duration = 30)\n",
    "    sound.export(os.path.join(out_dir, songname), format=\"wav\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61be2eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='highlight\\\\DPP\\\\阿爸的心肝寶貝.wav'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = r'highlight\\DPP'\n",
    "sound = AudioSegment.from_file(Path(f'./mp3/'+ '阿爸的心肝寶貝.wav'), start_second = 118, duration = 30)\n",
    "sound.export(os.path.join(out_dir, '阿爸的心肝寶貝.wav'), format=\"wav\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ca67cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spleeter.separator import Separator\n",
    "separator = Separator('spleeter:2stems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5c8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "mypath = r'DPP'\n",
    "files = [f for f in os.listdir(mypath) if os.path.isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae9e140",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:Downloading model archive https://github.com/deezer/spleeter/releases/download/v1.4.0/2stems.tar.gz\n",
      "INFO:spleeter:Validating archive checksum\n",
      "INFO:spleeter:Extracting downloaded 2stems archive\n",
      "INFO:spleeter:2stems model file(s) extracted\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models\\\\2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spleeter\\separator.py:146: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spleeter\\separator.py:146: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models\\2stems\\model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "# Batch separation export.\n",
    "for i in files:\n",
    "    separator.separate_to_file(join(mypath,i), '/stems/DPP', synchronous=False)\n",
    "\n",
    "# Wait for batch to finish.\n",
    "separator.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465de550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'pretrained_models\\\\2stems', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.7\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spleeter\\separator.py:146: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\spleeter\\separator.py:146: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models\\2stems\\model\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "for i in files[0:2]:\n",
    "    separator.separate_to_file(join(mypath,i), '/stem/DPP/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72d39ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
